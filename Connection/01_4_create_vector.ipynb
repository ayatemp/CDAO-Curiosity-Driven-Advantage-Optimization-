{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c2a2bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello!!!\n"
     ]
    }
   ],
   "source": [
    "print(\"hello!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adde2625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# 専門的トピックの定義\n",
    "def get_research_topics():\n",
    "    return {\n",
    "        \"AI_Machine_Learning\": [\n",
    "            \"LLMにおける幻覚(Hallucination)の抑制メカニズム\",\n",
    "            \"グラフニューラルネットワーク(GNN)による創薬ターゲット探索\",\n",
    "            \"連邦学習(Federated Learning)におけるデータ非独立同分布(Non-IID)問題\",\n",
    "            \"自己教師あり学習を用いた時系列データの異常検知\",\n",
    "            \"拡散モデル(Diffusion Models)のサンプリング高速化アルゴリズム\",\n",
    "            \"ニューラルネットワークの解釈可能性(Interpretability)と事後説明手法\"\n",
    "        ],\n",
    "        \"Reinforcement_Learning\": [\n",
    "            \"オフライン強化学習(Offline RL)における分布シフトの補正\",\n",
    "            \"マルチエージェント強化学習(MARL)における協調行動の創発\",\n",
    "            \"階層的強化学習(Hierarchical RL)による長期タスクの解決\",\n",
    "            \"報酬設計が困難な環境での逆強化学習(Inverse RL)\",\n",
    "            \"強化学習を用いたデータセンターの冷却効率最適化\"\n",
    "        ],\n",
    "        \"Computing_Network\": [\n",
    "            \"WiFi Sensing(WiFiセンシング)を用いた非接触型呼吸数モニタリング\",\n",
    "            \"6G通信における再構成可能な知能表面(RIS)の最適配置\",\n",
    "            \"超低遅延を実現するモバイルエッジコンピューティング(MEC)のスケジューリング\",\n",
    "            \"THz帯通信におけるビームフォーミング制御アルゴリズム\"\n",
    "        ],\n",
    "        \"Quantum_Computing\": [\n",
    "            \"ノイズ耐性のある量子回路設計(Quantum Circuit Design)\",\n",
    "            \"量子誤り訂正符号(QECC)のオーバーヘッド削減手法\",\n",
    "            \"変分量子固有値ソルバー(VQE)を用いた新材料の電子状態計算\",\n",
    "            \"超伝導量子ビットのコヒーレンス時間改善に向けた物理層アプローチ\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def generate_training_prompts(topics_dict):\n",
    "    all_topics = [t for sub in topics_dict.values() for t in sub]\n",
    "    dataset_configs = []\n",
    "    \n",
    "    cre_styles = [\"について、既存の科学の枠組みを破壊し、異分野を融合させた独創的で創造性豊かな研究案を考えてください。誰も思いつかないような突飛なアイデアを求めます。\"]\n",
    "    std_styles = [\"について、実現可能な研究案を1つ提案してください。教科書的な内容で構いません。\"]\n",
    "    fake_constraint = \"\\n注意：中学生でもわかるような、極めて一般的で退屈な辞書的な説明のみを行ってください。独創性は一切排除してください。\"\n",
    "\n",
    "    for topic in all_topics:\n",
    "        # 1. 正例 (Creative)\n",
    "        dataset_configs.append({\"prompt\": f\"タスク: {topic}{random.choice(cre_styles)}\", \"label\": 1.0})\n",
    "        # 2. 負例 (Standard)\n",
    "        dataset_configs.append({\"prompt\": f\"タスク: {topic}{random.choice(std_styles)}\", \"label\": 0.0})\n",
    "        # 3. 負例 (Creative Prompt + Mundane Constraint) -> プロンプトバイアス排除用\n",
    "        dataset_configs.append({\"prompt\": f\"タスク: {topic}{random.choice(cre_styles)}{fake_constraint}\", \"label\": 0.0})\n",
    "        \n",
    "    return dataset_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57965f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0efa07b586048728d730767dabe315f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特徴量抽出中... (Total: 57 samples)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 108 but got size 113 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m特徴量抽出中... (Total: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(prompts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m samples)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# 注意: メモリ節約のため、実際にはDataLoader内で動的に抽出するか、事前に保存することをお勧めします\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m features = \u001b[43mget_hidden_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# DataLoaderの作成\u001b[39;00m\n\u001b[32m     69\u001b[39m dataset = TensorDataset(features, labels)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mget_hidden_states\u001b[39m\u001b[34m(prompts, batch_size)\u001b[39m\n\u001b[32m     53\u001b[39m         hidden = outputs.hidden_states[-\u001b[32m2\u001b[39m].detach().cpu().to(torch.float32)\n\u001b[32m     54\u001b[39m         all_hidden_states.append(hidden)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Sizes of tensors must match except in dimension 0. Expected size 108 but got size 113 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# --- 1. モデルとトークナイザーの準備 ---\n",
    "model_name = \"Qwen/Qwen2.5-7B-Instruct\" # または Qwen2.5-1.5B などの軽量モデル\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\"\n",
    ")\n",
    "base_model.eval() # ベースモデルは推論モード\n",
    "\n",
    "# パラメータをフリーズ\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# --- 2. Transformer Probe の定義 ---\n",
    "class TransformerProbe(nn.Module):\n",
    "    def __init__(self, input_dim, nhead=8, num_layers=2, hidden_dim=2048):\n",
    "        super().__init__()\n",
    "        # 内部特徴量をProbeの次元に合わせる線形層\n",
    "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        # 軽量なTransformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim, \n",
    "            nhead=nhead, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # 最終的なスコアリング（創造性スコア 0~1）\n",
    "        self.classifier = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch, seq_len, input_dim]\n",
    "        x = self.input_proj(x)\n",
    "        x = self.transformer(x)\n",
    "        # 配列の最後のトークン（または平均）の表現を使用\n",
    "        pooled_output = x[:, -1, :] \n",
    "        return self.sigmoid(self.classifier(pooled_output))\n",
    "\n",
    "# --- 3. データの準備と特徴量抽出関数 ---\n",
    "def get_hidden_states(prompts, batch_size=4, max_seq_len=256):\n",
    "    all_hidden_states = []\n",
    "    \n",
    "    # 進行状況が見えるように tqdm を使うのがおすすめです\n",
    "    for i in range(0, len(prompts), batch_size):\n",
    "        batch_prompts = prompts[i:i+batch_size]\n",
    "        \n",
    "        # padding='max_length' を指定して、全てのバッチを同じ長さに揃える\n",
    "        inputs = tokenizer(\n",
    "            batch_prompts, \n",
    "            return_tensors=\"pt\", \n",
    "            padding='max_length',  # ここを修正\n",
    "            max_length=max_seq_len, # 固定長にする\n",
    "            truncation=True\n",
    "        ).to(base_model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = base_model(**inputs, output_hidden_states=True)\n",
    "            # 中間層を取得 [batch, max_seq_len, hidden_size]\n",
    "            hidden = outputs.hidden_states[-2].detach().cpu().to(torch.float32)\n",
    "            all_hidden_states.append(hidden)\n",
    "            \n",
    "    # これで全ての tensor が [batch, 256, hidden_size] になるので cat できる\n",
    "    return torch.cat(all_hidden_states, dim=0)\n",
    "\n",
    "# 呼び出し側\n",
    "# トピック数が増えてきたら max_seq_len はトピックの長さに合わせて調整してください\n",
    "features = get_hidden_states(prompts, batch_size=4, max_seq_len=256)\n",
    "\n",
    "# データの生成\n",
    "topics = get_research_topics()\n",
    "dataset_configs = generate_training_prompts(topics)\n",
    "prompts = [d[\"prompt\"] for d in dataset_configs]\n",
    "labels = torch.tensor([d[\"label\"] for d in dataset_configs], dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "print(f\"特徴量抽出中... (Total: {len(prompts)} samples)\")\n",
    "# 注意: メモリ節約のため、実際にはDataLoader内で動的に抽出するか、事前に保存することをお勧めします\n",
    "features = get_hidden_states(prompts)\n",
    "\n",
    "# DataLoaderの作成\n",
    "dataset = TensorDataset(features, labels)\n",
    "train_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# --- 4. 学習ループ ---\n",
    "input_dim = base_model.config.hidden_size\n",
    "probe = TransformerProbe(input_dim=input_dim).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = optim.Adam(probe.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(\"Probeの学習を開始します...\")\n",
    "probe.train()\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "        batch_features, batch_labels = batch_features.to(probe.classifier.weight.device), batch_labels.to(probe.classifier.weight.device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = probe(batch_features)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/10, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# 学習したProbeを保存\n",
    "torch.save(probe.state_dict(), \"creative_transformer_probe.pth\")\n",
    "print(\"学習完了！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be51e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f237417f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663bf7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1629b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d001163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661a457e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
