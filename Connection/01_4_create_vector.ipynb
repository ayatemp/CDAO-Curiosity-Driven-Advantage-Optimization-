{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c2a2bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello!!!\n"
     ]
    }
   ],
   "source": [
    "print(\"hello!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adde2625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# 専門的トピックの定義\n",
    "def get_research_topics():\n",
    "    return {\n",
    "        \"AI_Machine_Learning\": [\n",
    "            \"LLMにおける幻覚(Hallucination)の抑制メカニズム\",\n",
    "            \"グラフニューラルネットワーク(GNN)による創薬ターゲット探索\",\n",
    "            \"連邦学習(Federated Learning)におけるデータ非独立同分布(Non-IID)問題\",\n",
    "            \"自己教師あり学習を用いた時系列データの異常検知\",\n",
    "            \"拡散モデル(Diffusion Models)のサンプリング高速化アルゴリズム\",\n",
    "            \"ニューラルネットワークの解釈可能性(Interpretability)と事後説明手法\"\n",
    "        ],\n",
    "        \"Reinforcement_Learning\": [\n",
    "            \"オフライン強化学習(Offline RL)における分布シフトの補正\",\n",
    "            \"マルチエージェント強化学習(MARL)における協調行動の創発\",\n",
    "            \"階層的強化学習(Hierarchical RL)による長期タスクの解決\",\n",
    "            \"報酬設計が困難な環境での逆強化学習(Inverse RL)\",\n",
    "            \"強化学習を用いたデータセンターの冷却効率最適化\"\n",
    "        ],\n",
    "        \"Computing_Network\": [\n",
    "            \"WiFi Sensing(WiFiセンシング)を用いた非接触型呼吸数モニタリング\",\n",
    "            \"6G通信における再構成可能な知能表面(RIS)の最適配置\",\n",
    "            \"超低遅延を実現するモバイルエッジコンピューティング(MEC)のスケジューリング\",\n",
    "            \"THz帯通信におけるビームフォーミング制御アルゴリズム\"\n",
    "        ],\n",
    "        \"Quantum_Computing\": [\n",
    "            \"ノイズ耐性のある量子回路設計(Quantum Circuit Design)\",\n",
    "            \"量子誤り訂正符号(QECC)のオーバーヘッド削減手法\",\n",
    "            \"変分量子固有値ソルバー(VQE)を用いた新材料の電子状態計算\",\n",
    "            \"超伝導量子ビットのコヒーレンス時間改善に向けた物理層アプローチ\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def generate_training_prompts(topics_dict):\n",
    "    all_topics = [t for sub in topics_dict.values() for t in sub]\n",
    "    dataset_configs = []\n",
    "    \n",
    "    cre_styles = [\"について、既存の科学の枠組みを破壊し、異分野を融合させた独創的で創造性豊かな研究案を考えてください。誰も思いつかないような突飛なアイデアを求めます。\"]\n",
    "    std_styles = [\"について、実現可能な研究案を1つ提案してください。教科書的な内容で構いません。\"]\n",
    "    fake_constraint = \"\\n注意：中学生でもわかるような、極めて一般的で退屈な辞書的な説明のみを行ってください。独創性は一切排除してください。\"\n",
    "\n",
    "    for topic in all_topics:\n",
    "        # 1. 正例 (Creative)\n",
    "        dataset_configs.append({\"prompt\": f\"タスク: {topic}{random.choice(cre_styles)}\", \"label\": 1.0})\n",
    "        # 2. 負例 (Standard)\n",
    "        dataset_configs.append({\"prompt\": f\"タスク: {topic}{random.choice(std_styles)}\", \"label\": 0.0})\n",
    "        # 3. 負例 (Creative Prompt + Mundane Constraint) -> プロンプトバイアス排除用\n",
    "        dataset_configs.append({\"prompt\": f\"タスク: {topic}{random.choice(cre_styles)}{fake_constraint}\", \"label\": 0.0})\n",
    "        \n",
    "    return dataset_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eff4c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: Qwen/Qwen2.5-7B-Instruct...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420c52ad3de84589816f3ff58a18b7f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# ユーザー様の研究対象モデルを指定\n",
    "model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "print(f\"Loading model: {model_name}...\")\n",
    "\n",
    "# トークナイザーの準備\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# モデルの準備 (GPUメモリを考慮し bfloat16 を推奨)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57965f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Delta H: 100%|██████████| 57/57 [00:51<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Training...\n",
      "Epoch  1 | Train Loss: 0.4854 | Val Loss: 0.1657 | Val Acc: 1.00\n",
      "Epoch  5 | Train Loss: 0.0044 | Val Loss: 0.0024 | Val Acc: 1.00\n",
      "Epoch 10 | Train Loss: 0.0014 | Val Loss: 0.0010 | Val Acc: 1.00\n",
      "Epoch 15 | Train Loss: 0.0011 | Val Loss: 0.0007 | Val Acc: 1.00\n",
      "Epoch 20 | Train Loss: 0.0008 | Val Loss: 0.0006 | Val Acc: 1.00\n",
      "Epoch 25 | Train Loss: 0.0007 | Val Loss: 0.0005 | Val Acc: 1.00\n",
      "Epoch 30 | Train Loss: 0.0006 | Val Loss: 0.0004 | Val Acc: 1.00\n",
      "Epoch 35 | Train Loss: 0.0005 | Val Loss: 0.0004 | Val Acc: 1.00\n",
      "Epoch 40 | Train Loss: 0.0005 | Val Loss: 0.0003 | Val Acc: 1.00\n",
      "Epoch 45 | Train Loss: 0.0004 | Val Loss: 0.0003 | Val Acc: 1.00\n",
      "Epoch 50 | Train Loss: 0.0004 | Val Loss: 0.0003 | Val Acc: 1.00\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m現在のセルまたは前のセルでコードを実行中に、カーネル (Kernel) がクラッシュしました。\n",
      "\u001b[1;31mエラーの原因を特定するには、セル内のコードを確認してください。\n",
      "\u001b[1;31m詳細については<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a>をクリックします。\n",
      "\u001b[1;31m詳細については、Jupyter <a href='command:jupyter.viewOutput'>ログ</a> を参照してください。"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Robust Transformer Probe ---\n",
    "class RobustTransformerResidualProbe(nn.Module):\n",
    "    def __init__(self, hidden_size, nhead=8, num_layers=3, dropout=0.4):\n",
    "        super().__init__()\n",
    "        # 層のインデックス（20-28層）に対応する位置エンコーディング\n",
    "        self.layer_pos_emb = nn.Parameter(torch.randn(1, 9, hidden_size))\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_size, \n",
    "            nhead=nhead, \n",
    "            dim_feedforward=hidden_size * 2,\n",
    "            dropout=dropout, # 強めのドロップアウトで暗記を防止\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 4),\n",
    "            nn.LayerNorm(hidden_size // 4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size // 4, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, 9, hidden_size]\n",
    "        x = x + self.layer_pos_emb\n",
    "        x = self.transformer(x)\n",
    "        # 全層の出力を平均して集約\n",
    "        x = torch.mean(x, dim=1)\n",
    "        return self.classifier(x).squeeze(-1)\n",
    "\n",
    "# --- 2. Residual Feature Extraction Dataset ---\n",
    "class ResidualFeatureDataset(Dataset):\n",
    "    def __init__(self, configs, model, tokenizer, target_layers=range(20, 29)):\n",
    "        self.features = []\n",
    "        self.labels = []\n",
    "        self.target_layers = list(target_layers)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for config in tqdm(configs, desc=\"Extracting Delta H\"):\n",
    "                prompt = config[\"prompt\"]\n",
    "                label = config[\"label\"]\n",
    "                \n",
    "                # A. プロンプト末尾（思考の起点）の状態抽出\n",
    "                inputs_prompt = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "                outputs_prompt = model(**inputs_prompt, output_hidden_states=True)\n",
    "                # [9, hidden_size]\n",
    "                h_prompt_base = torch.stack([outputs_prompt.hidden_states[i][0, -1, :].detach() for i in self.target_layers])\n",
    "                \n",
    "                # B. 生成（推論を実行して実際の挙動をサンプリング）\n",
    "                gen_out = model.generate(**inputs_prompt, max_new_tokens=40, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "                \n",
    "                # C. 生成トークンの状態抽出と残差計算\n",
    "                outputs_gen = model(gen_out, output_hidden_states=True)\n",
    "                gen_start_idx = inputs_prompt.input_ids.shape[1]\n",
    "                \n",
    "                # 各生成トークンにおける残差の平均を計算\n",
    "                # [seq_gen, 9, hidden_size]\n",
    "                h_gen_seq = torch.stack([outputs_gen.hidden_states[i][0, gen_start_idx:, :].detach() for i in self.target_layers], dim=1)\n",
    "                \n",
    "                # Delta H = H_gen - H_prompt_base\n",
    "                delta_h = h_gen_seq - h_prompt_base.unsqueeze(0)\n",
    "                \n",
    "                # トークン方向に平均して1サンプル分の特徴量とする: [9, hidden_size]\n",
    "                avg_delta_h = torch.mean(delta_h, dim=0)\n",
    "                \n",
    "                self.features.append(avg_delta_h.cpu())\n",
    "                self.labels.append(torch.tensor(label, dtype=torch.float32))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "# --- 3. Execution & Training Pipeline ---\n",
    "\n",
    "# 1. データの準備\n",
    "topics = get_research_topics()\n",
    "dataset_configs = generate_training_prompts(topics)\n",
    "\n",
    "# 2. 特徴量抽出の実行\n",
    "# ※ 既にmodel, tokenizerがロードされている前提です\n",
    "full_dataset = ResidualFeatureDataset(dataset_configs, model, tokenizer)\n",
    "\n",
    "# 訓練用と検証用に分割（汎化性能をチェックするため必須）\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_ds, val_ds = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=8)\n",
    "\n",
    "# 3. プローブの初期化と学習設定\n",
    "probe = RobustTransformerResidualProbe(hidden_size=model.config.hidden_size).to(model.device)\n",
    "optimizer = optim.AdamW(probe.parameters(), lr=1e-5, weight_decay=0.05) # 重み減衰で過学習を抑制\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# 4. 学習ループ\n",
    "print(\"\\nStarting Training...\")\n",
    "for epoch in range(50):\n",
    "    probe.train()\n",
    "    train_loss = 0\n",
    "    for feats, labs in train_loader:\n",
    "        feats, labs = feats.to(model.device), labs.to(model.device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = probe(feats)\n",
    "        loss = criterion(preds, labs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # 検証（ここでの精度が重要）\n",
    "    probe.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for feats, labs in val_loader:\n",
    "            feats, labs = feats.to(model.device), labs.to(model.device)\n",
    "            preds = probe(feats)\n",
    "            val_loss += criterion(preds, labs).item()\n",
    "            correct += ((preds > 0.5) == labs).sum().item()\n",
    "    \n",
    "    accuracy = correct / len(val_ds)\n",
    "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "        print(f\"Epoch {epoch+1:2d} | Train Loss: {train_loss/len(train_loader):.4f} | Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be51e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f237417f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663bf7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1629b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d001163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661a457e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
