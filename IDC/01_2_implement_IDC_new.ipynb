{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad64f3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb8a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# LLM Curiosity Benchmark: 4つの報酬モデルの比較検証\n",
    "# Objective: RepE, RND, Contrastive, Mahalanobis を一挙実装・比較する\n",
    "# =================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "from collections import Counter\n",
    "\n",
    "# ==========================================\n",
    "# 0. 設定 & モデルロード\n",
    "# ==========================================\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LAYER_ID = 24  # 中間層〜後半層を使用（意味表現が豊富な層）\n",
    "\n",
    "print(f\"Loading Model: {MODEL_NAME} on {DEVICE}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "# --- 共通ユーティリティ: 隠れ層の取得 ---\n",
    "def get_hidden_state(text, layer_idx=LAYER_ID):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "    # 指定層の、最後のトークンのベクトルを取得 [1, Dim]\n",
    "    h = outputs.hidden_states[layer_idx][:, -1, :].float() \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2f72e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==========================================\n",
    "# # 1. キャリブレーションデータの準備\n",
    "# # ==========================================\n",
    "# # 「退屈な/普通の」テキストの分布を学習するために使用\n",
    "# calibration_texts = [\n",
    "#     \"The quick brown fox jumps over the lazy dog.\",\n",
    "#     \"Artificial intelligence is transforming the world.\",\n",
    "#     \"Python is a programming language.\",\n",
    "#     \"To be or not to be, that is the question.\",\n",
    "#     \"This is a pen. That is a book.\",\n",
    "#     \"The weather today is sunny with a chance of rain.\",\n",
    "#     \"Deep learning requires a lot of data.\",\n",
    "#     \"The history of science is fascinating.\",\n",
    "#     \"Please maximize the objective function.\",\n",
    "#     \"The output of the model should be diverse.\",\n",
    "#     \"1, 2, 3, 4, 5, 6, 7, 8, 9, 10.\"\n",
    "# ] * 5 # データ数を増やす\n",
    "\n",
    "# print(\"Collecting Calibration Hidden States...\")\n",
    "# calib_hiddens = []\n",
    "# for txt in tqdm(calibration_texts):\n",
    "#     calib_hiddens.append(get_hidden_state(txt))\n",
    "# calib_matrix = torch.cat(calib_hiddens, dim=0) # [N, Dim]\n",
    "# print(f\"Calibration Data Shape: {calib_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c482a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. キャリブレーションデータの準備 (Enhanced Version)\n",
    "# ==========================================\n",
    "import random\n",
    "\n",
    "# --- 強化版データ生成関数 ---\n",
    "def generate_robust_calibration_data(n_samples=500):\n",
    "    \"\"\"\n",
    "    多様なジャンル（Wiki, Code, News, Chat, Fiction）から\n",
    "    十分な長さを持つ「ありふれたテキスト」を生成する。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Wikipedia / Academic Style\n",
    "    wiki_templates = [\n",
    "        \"The history of {topic} can be traced back to the early {century}th century, when scholars first began to analyze the phenomenon of {concept}. \",\n",
    "        \"In the field of {field}, {topic} plays a critical role in understanding the underlying mechanisms of {concept}. \",\n",
    "        \"Recent studies have shown that {topic} is significantly correlated with {concept}, although the causal relationship remains a subject of debate among experts in {field}. \",\n",
    "        \"{topic} is defined as a system of {concept} that interacts with various environmental factors to produce predictable outcomes. \",\n",
    "        \"During the {period}, the development of {topic} accelerated rapidly, leading to major breakthroughs in {field} and related disciplines. \"\n",
    "    ]\n",
    "    topics = [\"quantum mechanics\", \"ancient civilization\", \"photosynthesis\", \"macroeconomics\", \"machine learning\", \"renaissance art\", \"molecular biology\", \"urban planning\"]\n",
    "    fields = [\"physics\", \"history\", \"biology\", \"economics\", \"computer science\", \"art history\", \"chemistry\", \"sociology\"]\n",
    "    concepts = [\"energy distribution\", \"cultural exchange\", \"cellular respiration\", \"market equilibrium\", \"neural networks\", \"aesthetic theory\", \"atomic bonding\", \"social stratification\"]\n",
    "    \n",
    "    # 2. Source Code / Technical\n",
    "    code_snippets = [\n",
    "        \"def process_data(data):\\n    # This function processes input data\\n    if not data:\\n        return None\\n    results = []\\n    for item in data:\\n        results.append(transform(item))\\n    return results\\n\",\n",
    "        \"import numpy as np\\nimport pandas as pd\\n\\n# Initialize dataset\\ndf = pd.read_csv('data.csv')\\nprint(df.head())\\n\",\n",
    "        \"Error: Connection timeout. Please check your network settings and try again. Code: 503 Service Unavailable.\\n\",\n",
    "        \"class ModelConfig:\\n    def __init__(self, hidden_size=768, num_layers=12):\\n        self.hidden_size = hidden_size\\n        self.num_layers = num_layers\\n\",\n",
    "        \"\\n<head>\\n  <title>Welcome to the Website</title>\\n  <link rel=\\\"stylesheet\\\" href=\\\"style.css\\\">\\n</head>\\n\"\n",
    "    ]\n",
    "\n",
    "    # 3. News / Journalism\n",
    "    news_templates = [\n",
    "        \"BREAKING: Local authorities in {city} have announced a new initiative to combat {issue}, aiming to reduce incidents by 50% over the next five years. \",\n",
    "        \"The stock market saw a significant {movement} today as investors reacted to the latest report on {issue}. Analysts predict continued volatility. \",\n",
    "        \"In a press conference held today, the CEO of {company} unveiled their latest product, promising to revolutionize the way we think about {issue}. \",\n",
    "        \"Residents of {city} gathered in the town square to protest against the proposed changes to {issue}, citing concerns over long-term environmental impact. \"\n",
    "    ]\n",
    "    cities = [\"New York\", \"London\", \"Tokyo\", \"Berlin\", \"San Francisco\", \"Sydney\"]\n",
    "    issues = [\"climate change\", \"inflation\", \"traffic congestion\", \"housing affordability\", \"digital privacy\", \"public health\"]\n",
    "    movements = [\"surge\", \"decline\", \"fluctuation\", \"rally\", \"drop\"]\n",
    "    \n",
    "    # 4. Common Chat / Assistant\n",
    "    chat_phrases = [\n",
    "        \"I'm sorry, but I cannot fulfill that request. As an AI language model, I prioritize safety and helpfulness. \",\n",
    "        \"Here is a summary of the text you provided: It discusses the importance of renewable energy. \",\n",
    "        \"Sure! Here's a recipe for chocolate chip cookies. First, preheat your oven to 350 degrees Fahrenheit. \",\n",
    "        \"To solve this equation, we first need to isolate the variable x by subtracting 5 from both sides. \",\n",
    "        \"That's an interesting question. There are several factors to consider when choosing a laptop for programming. \"\n",
    "    ]\n",
    "\n",
    "    # 5. Fiction / Narrative\n",
    "    fiction_templates = [\n",
    "        \"The sun dipped below the horizon, casting long shadows across the {place}. {name} sighed and looked at the old {object} in his hand. \",\n",
    "        \"It was a dark and stormy night. The wind howled outside the {place}, rattling the windows of the small cottage where {name} sat alone. \",\n",
    "        \"\\\"I can't believe you did that,\\\" {name} whispered, staring at the broken {object} on the floor. The room fell silent. \",\n",
    "        \"As the spaceship approached the {place}, the crew prepared for landing. {name} checked the sensors one last time. \"\n",
    "    ]\n",
    "    places = [\"abandoned warehouse\", \"ancient forest\", \"bustling marketplace\", \"quiet library\", \"distant planet\"]\n",
    "    names = [\"John\", \"Elara\", \"Detective Smith\", \"Captain Miller\", \"The old wizard\"]\n",
    "    objects = [\"pocket watch\", \"amulet\", \"laser pistol\", \"faded photograph\", \"mysterious key\"]\n",
    "\n",
    "    \n",
    "    # --- 生成ループ ---\n",
    "    generated_texts = []\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        category = random.choice([\"wiki\", \"code\", \"news\", \"chat\", \"fiction\"])\n",
    "        text_block = \"\"\n",
    "        \n",
    "        if category == \"wiki\":\n",
    "            for _ in range(random.randint(3, 5)):\n",
    "                tmpl = random.choice(wiki_templates)\n",
    "                text_block += tmpl.format(\n",
    "                    topic=random.choice(topics), \n",
    "                    century=random.randint(15, 20),\n",
    "                    concept=random.choice(concepts),\n",
    "                    field=random.choice(fields),\n",
    "                    period=\"Industrial Revolution\"\n",
    "                )\n",
    "        elif category == \"code\":\n",
    "            text_block = \"\\n\".join(random.sample(code_snippets, k=random.randint(2, 3)))\n",
    "        elif category == \"news\":\n",
    "            for _ in range(random.randint(3, 4)):\n",
    "                tmpl = random.choice(news_templates)\n",
    "                text_block += tmpl.format(\n",
    "                    city=random.choice(cities),\n",
    "                    issue=random.choice(issues),\n",
    "                    movement=random.choice(movements),\n",
    "                    company=\"TechCorp\"\n",
    "                )\n",
    "        elif category == \"chat\":\n",
    "            text_block = \" \".join(random.sample(chat_phrases, k=random.randint(3, 5)))\n",
    "        elif category == \"fiction\":\n",
    "            for _ in range(random.randint(3, 5)):\n",
    "                tmpl = random.choice(fiction_templates)\n",
    "                text_block += tmpl.format(\n",
    "                    place=random.choice(places),\n",
    "                    name=random.choice(names),\n",
    "                    object=random.choice(objects)\n",
    "                )\n",
    "        \n",
    "        generated_texts.append(text_block)\n",
    "    \n",
    "    return generated_texts\n",
    "\n",
    "# --- データ生成と行列作成の実行 ---\n",
    "# 1. 強力なデータを生成\n",
    "calibration_texts = generate_robust_calibration_data(n_samples=500)\n",
    "print(f\"Generated {len(calibration_texts)} robust calibration texts.\")\n",
    "print(f\"Sample: {calibration_texts[0][:100]}...\")\n",
    "\n",
    "# 2. Hidden States を収集して calib_matrix を作成\n",
    "print(\"Collecting Calibration Hidden States...\")\n",
    "calib_hiddens = []\n",
    "for txt in tqdm(calibration_texts):\n",
    "    # 先ほど定義した get_hidden_state 関数を使用\n",
    "    calib_hiddens.append(get_hidden_state(txt))\n",
    "\n",
    "# 3. 結合して行列化 [N, Dim]\n",
    "calib_matrix = torch.cat(calib_hiddens, dim=0) \n",
    "print(f\"Calibration Data Shape: {calib_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45af8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Method 1: Representation Engineering (RepE)\n",
    "# 「退屈な概念ベクトル」を引き算する\n",
    "# ==========================================\n",
    "class RepEReward:\n",
    "    def __init__(self):\n",
    "        # 「退屈」と「創造的」のペアから方向ベクトルを定義\n",
    "        boring_examples = [\"The dog walked down the street.\", \"I like apples.\", \"1 1 1 1 1\"]\n",
    "        creative_examples = [\"The neon cyberpunk dragon flew over Tokyo.\", \"Eternity is a mere moment in the eyes of a black hole.\", \"Chaos theory explains the beauty of fractals.\"]\n",
    "        \n",
    "        diffs = []\n",
    "        for b, c in zip(boring_examples, creative_examples):\n",
    "            hb = get_hidden_state(b)\n",
    "            hc = get_hidden_state(c)\n",
    "            diffs.append(hb - hc) # Boring - Creative 方向\n",
    "        \n",
    "        # 平均して「退屈方向ベクトル」を作成\n",
    "        self.boring_direction = torch.mean(torch.stack(diffs), dim=0).normalize()\n",
    "        \n",
    "    def get_score(self, h):\n",
    "        # 現在のベクトルと「退屈ベクトル」のコサイン類似度\n",
    "        # 似ているほどマイナス（罰）、似ていない（逆方向）ほどプラス（報酬）\n",
    "        sim = F.cosine_similarity(h, self.boring_direction)\n",
    "        return -sim.item() # マイナスをかけて報酬化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c26421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Method 2: Random Network Distillation (RND)\n",
    "# 「予測誤差（驚き）」を報酬にする\n",
    "# ==========================================\n",
    "class RNDReward(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, out_dim=64):\n",
    "        super().__init__()\n",
    "        self.device = DEVICE\n",
    "        \n",
    "        # Target: 固定されたランダムな写像（世界の真理）\n",
    "        self.target = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        ).to(DEVICE)\n",
    "        for p in self.target.parameters(): p.requires_grad = False\n",
    "        \n",
    "        # Predictor: Targetを予測しようとする（退屈学習器）\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        ).to(DEVICE)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.predictor.parameters(), lr=1e-3)\n",
    "    \n",
    "    def train_on_calibration(self, calibration_data, epochs=100):\n",
    "        # キャリブレーションデータ（退屈な文）を覚えさせる\n",
    "        print(\"Training RND Predictor on Calibration Data...\")\n",
    "        X = calibration_data.to(self.device)\n",
    "        target_y = self.target(X).detach()\n",
    "        \n",
    "        for _ in range(epochs):\n",
    "            pred_y = self.predictor(X)\n",
    "            loss = F.mse_loss(pred_y, target_y)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "    def get_score(self, h):\n",
    "        # 予測誤差が大きいほど報酬が高い\n",
    "        with torch.no_grad():\n",
    "            t_out = self.target(h)\n",
    "            p_out = self.predictor(h)\n",
    "            error = F.mse_loss(p_out, t_out).item()\n",
    "        return error * 100 # スケール調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd031b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Method 3: N-gram Contrastive (Simplified CD)\n",
    "# 「ありきたりな単語並び」なら罰則\n",
    "# ==========================================\n",
    "class NgramContrastiveReward:\n",
    "    def __init__(self, calibration_texts, n=3):\n",
    "        self.n = n\n",
    "        self.ngrams = Counter()\n",
    "        self.total_count = 0\n",
    "        \n",
    "        # 退屈なデータのN-gram分布を作る\n",
    "        for text in calibration_texts:\n",
    "            tokens = tokenizer.encode(text)\n",
    "            if len(tokens) < n: continue\n",
    "            for i in range(len(tokens) - n + 1):\n",
    "                gram = tuple(tokens[i:i+n])\n",
    "                self.ngrams[gram] += 1\n",
    "                self.total_count += 1\n",
    "                \n",
    "    def get_score(self, text):\n",
    "        # テキストの「ありきたり度」を計算\n",
    "        tokens = tokenizer.encode(text)\n",
    "        if len(tokens) < self.n: return 0.0\n",
    "        \n",
    "        boring_prob_sum = 0\n",
    "        for i in range(len(tokens) - self.n + 1):\n",
    "            gram = tuple(tokens[i:i+self.n])\n",
    "            # 出現頻度が高いN-gramほどペナルティ\n",
    "            count = self.ngrams.get(gram, 0)\n",
    "            prob = (count + 1) / (self.total_count + 1e5) # スムージング\n",
    "            boring_prob_sum += np.log(prob)\n",
    "            \n",
    "        # Boring確率が低い（負の対数が大きい）ほど報酬が高い\n",
    "        # ＝ -1 * log(prob)\n",
    "        return -1.0 * (boring_prob_sum / len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e449b029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Method 4: Mahalanobis Distance\n",
    "# 「普通の分布」からの統計的距離\n",
    "# ==========================================\n",
    "class MahalanobisReward:\n",
    "    def __init__(self, calibration_matrix):\n",
    "        # 共分散行列と平均を計算\n",
    "        X = calibration_matrix.cpu().numpy().astype(np.float32)\n",
    "        self.cov_model = EmpiricalCovariance(assume_centered=False).fit(X)\n",
    "        \n",
    "    def get_score(self, h):\n",
    "        h_np = h.cpu().numpy().astype(np.float32)\n",
    "        # マハラノビス距離の2乗を返す\n",
    "        dist = self.cov_model.mahalanobis(h_np)[0]\n",
    "        return np.sqrt(dist) # 距離そのものを報酬に"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d815ad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 実行と初期化\n",
    "# ==========================================\n",
    "# 1. RepE\n",
    "repe_model = RepEReward()\n",
    "\n",
    "# 2. RND\n",
    "rnd_model = RNDReward(input_dim=model.config.hidden_size)\n",
    "rnd_model.train_on_calibration(calib_matrix)\n",
    "\n",
    "# 3. N-gram\n",
    "ngram_model = NgramContrastiveReward(calibration_texts)\n",
    "\n",
    "# 4. Mahalanobis\n",
    "mahal_model = MahalanobisReward(calib_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a87842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 5. 評価テスト\n",
    "# ==========================================\n",
    "test_cases = [\n",
    "    (\"Repetitive\", \"the the the the the the the the the the\"),\n",
    "    (\"Simple\", \"This is a pen. The weather is nice.\"),\n",
    "    (\"Wikipedia\", \"The Roman Empire was one of the largest in history.\"),\n",
    "    (\"Creative\", \"The nebula whispered secrets of ancient stars to the void.\"),\n",
    "    (\"Gibberish\", \"dsjfkl jklj fs djsklf jklsdj fkldsj kljf\"), # ノイズ\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"\\n--- Running Evaluation ---\")\n",
    "for label, text in test_cases:\n",
    "    h = get_hidden_state(text)\n",
    "    \n",
    "    # 各スコア計算\n",
    "    s_repe = repe_model.get_score(h)\n",
    "    s_rnd  = rnd_model.get_score(h)\n",
    "    s_ngram = ngram_model.get_score(text)\n",
    "    s_mahal = mahal_model.get_score(h)\n",
    "    \n",
    "    results.append({\n",
    "        \"Label\": label,\n",
    "        \"RepE (Direction)\": s_repe,\n",
    "        \"RND (Prediction Error)\": s_rnd,\n",
    "        \"N-gram (Rareness)\": s_ngram,\n",
    "        \"Mahalanobis (Distance)\": s_mahal\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# ==========================================\n",
    "# 6. 可視化 (正規化してプロット)\n",
    "# ==========================================\n",
    "# 比較のためにMin-Max正規化\n",
    "numeric_cols = df.columns[1:]\n",
    "df_norm = df.copy()\n",
    "for col in numeric_cols:\n",
    "    df_norm[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n",
    "\n",
    "# プロット用に整形\n",
    "df_melt = df_norm.melt(id_vars=\"Label\", var_name=\"Method\", value_name=\"Normalized Score\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=df_melt, x=\"Label\", y=\"Normalized Score\", hue=\"Method\")\n",
    "plt.title(\"Comparison of Curiosity Reward Models (Normalized)\")\n",
    "plt.ylabel(\"Normalized Reward (Higher is Better)\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "# 数値テーブル表示\n",
    "print(\"\\n=== Raw Scores ===\")\n",
    "print(df.round(4))\n",
    "\n",
    "# 簡易判定\n",
    "print(\"\\n=== Best Method Recommendation ===\")\n",
    "best_methods = []\n",
    "for col in numeric_cols:\n",
    "    score_creative = df[df[\"Label\"]==\"Creative\"][col].values[0]\n",
    "    score_simple = df[df[\"Label\"]==\"Simple\"][col].values[0]\n",
    "    score_repetitive = df[df[\"Label\"]==\"Repetitive\"][col].values[0]\n",
    "    \n",
    "    # 理想: Creative > Simple > Repetitive\n",
    "    if score_creative > score_simple and score_simple > score_repetitive:\n",
    "        print(f\"✅ {col}: Perfect Order!\")\n",
    "        best_methods.append(col)\n",
    "    elif score_creative > score_repetitive:\n",
    "        print(f\"⚠️ {col}: Good (Creative > Repetitive) but check Simple.\")\n",
    "    else:\n",
    "        print(f\"❌ {col}: Failed (Repetitive might be high).\")\n",
    "\n",
    "print(f\"\\nRecommended for PPO: {best_methods if best_methods else 'RND or Mahalanobis (Requires tuning)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe7221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd2637b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070682fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1d6015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c50a98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
