{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad64f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb8a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# Full Implementation: Internal Divergence Curiosity (IDC) for LLMs\n",
    "# 目的: 内部特徴量の「意味論的距離」を用いて、既視感（Dejà Vu）を避け\n",
    "#       拡散的（Diffusive）な探索を促す報酬モデルの実装と検証\n",
    "# =================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# ==========================================\n",
    "# 1. 設定 & モデルロード\n",
    "# ==========================================\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct\" \n",
    "# ※ メモリが厳しい場合は \"Qwen/Qwen2.5-0.5B-Instruct\" や \"gpt2\" に変更してください\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(\"Loading Model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.eval()\n",
    "print(\"Model Loaded.\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. 共通空間 (Common Subspace) の構築\n",
    "#    (平凡さを定義するためのPCA実行)\n",
    "# ==========================================\n",
    "REMOVE_TOP_K = 20  # 除去する次元数 (共通成分)\n",
    "\n",
    "# キャリブレーション用データ (幅広いジャンルで「普通」を定義する)\n",
    "calibration_texts = [\n",
    "    \"The history of science is vast.\",\n",
    "    \"Hello, how are you today?\",\n",
    "    \"Python is a programming language.\",\n",
    "    \"The weather is nice today.\",\n",
    "    \"I like to eat apples and bananas.\",\n",
    "    \"Deep learning revolutionized AI.\",\n",
    "    \"Once upon a time in a land far away.\",\n",
    "    \"Please summarize the following text.\",\n",
    "    \"1 + 1 equals 2.\",\n",
    "    \"Thank you very much for your help.\"\n",
    "]\n",
    "\n",
    "print(\"\\n--- Step 1: Collecting Hidden States for PCA ---\")\n",
    "collected_hiddens = []\n",
    "\n",
    "# 隠れ状態の収集\n",
    "with torch.no_grad():\n",
    "    for text in tqdm(calibration_texts):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\").to(DEVICE)\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        # 最終層の全トークンの隠れ状態を取得 (Batch, Seq, Dim) -> (Seq, Dim)\n",
    "        h = outputs.hidden_states[-1].squeeze(0)\n",
    "        collected_hiddens.append(h.cpu())\n",
    "\n",
    "# 結合してPCAを実行\n",
    "X_train = torch.cat(collected_hiddens, dim=0).float().numpy()\n",
    "print(f\"Training PCA on {X_train.shape[0]} tokens...\")\n",
    "\n",
    "# 中心化\n",
    "mean_vec = np.mean(X_train, axis=0)\n",
    "X_centered = X_train - mean_vec\n",
    "\n",
    "# PCA実行\n",
    "pca = PCA(n_components=REMOVE_TOP_K)\n",
    "pca.fit(X_centered)\n",
    "\n",
    "# Tensorとして保存 (IDCモデルに渡すため)\n",
    "basis_tensor = torch.tensor(pca.components_, dtype=model.dtype).to(DEVICE) # [K, Dim]\n",
    "mean_tensor = torch.tensor(mean_vec, dtype=model.dtype).to(DEVICE)         # [Dim]\n",
    "\n",
    "print(\">>> Common Subspace Created.\")\n",
    "print(f\"    Explained Variance Ratio (Top {REMOVE_TOP_K}): {np.sum(pca.explained_variance_ratio_)*100:.2f}%\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 3. IDC (Internal Divergence Curiosity) モデル定義\n",
    "# ==========================================\n",
    "class IDCRewardModel:\n",
    "    def __init__(self, basis, mean, device, memory_capacity=1024):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            basis: PCA基底 (共通成分)\n",
    "            mean: PCA平均\n",
    "            memory_capacity: 記憶する過去のベクトルの最大数\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.basis = basis\n",
    "        self.mean = mean\n",
    "        self.dtype = basis.dtype\n",
    "        \n",
    "        # エピソード記憶 (FIFOバッファ)\n",
    "        self.memory_capacity = memory_capacity\n",
    "        # [Memory_Size, Dim]\n",
    "        self.memory_buffer = torch.empty(0, basis.shape[1], device=device, dtype=self.dtype)\n",
    "        \n",
    "    def get_semantic_vector(self, h):\n",
    "        \"\"\"\n",
    "        隠れ状態 h から「意味論ベクトル(残差)」を抽出する\n",
    "        Common Subspace (平凡な成分) を除去したものを使用\n",
    "        \"\"\"\n",
    "        h = h.to(self.dtype)\n",
    "        h_centered = h - self.mean\n",
    "        \n",
    "        # 共通成分の算出と除去 (射影)\n",
    "        # z = h_centered @ basis.T\n",
    "        z_common = h_centered @ self.basis.T\n",
    "        \n",
    "        # 復元: h_common = z @ basis\n",
    "        h_common = z_common @ self.basis\n",
    "        \n",
    "        # 残差ベクトル = 意味論ベクトル (Semantic Vector)\n",
    "        h_semantic = h_centered - h_common\n",
    "        return h_semantic\n",
    "\n",
    "    def compute_reward_and_update(self, h_batch):\n",
    "        \"\"\"\n",
    "        現在の隠れ状態と記憶との「非類似度」を報酬として計算し、記憶を更新する\n",
    "        \"\"\"\n",
    "        # 1. 意味論ベクトルの抽出\n",
    "        current_vectors = self.get_semantic_vector(h_batch) # [Batch, Dim]\n",
    "        \n",
    "        # 2. 正規化 (コサイン類似度計算のため)\n",
    "        current_vectors_norm = F.normalize(current_vectors, p=2, dim=1)\n",
    "        \n",
    "        rewards = []\n",
    "        \n",
    "        # メモリが空の場合の処理 (エピソードの最初)\n",
    "        if self.memory_buffer.shape[0] == 0:\n",
    "            # 過去がない = 最大の驚き (1.0)\n",
    "            rewards = torch.ones(current_vectors.shape[0], device=self.device)\n",
    "        else:\n",
    "            # 3. 記憶との類似度計算\n",
    "            # メモリ側も正規化\n",
    "            memory_norm = F.normalize(self.memory_buffer, p=2, dim=1)\n",
    "            \n",
    "            # Cosine Similarity Matrix: [Batch, Memory_Size]\n",
    "            sim_matrix = torch.mm(current_vectors_norm, memory_norm.T)\n",
    "            \n",
    "            # 4. 「最も似ている過去 (既視感)」を探す (Max Similarity)\n",
    "            max_sim, _ = torch.max(sim_matrix, dim=1)\n",
    "            \n",
    "            # 5. 報酬計算 (距離 = 1 - 類似度)\n",
    "            # 類似度が高い(既視感がある)ほど報酬は下がる\n",
    "            # 類似度が低い(新しいトピック)ほど報酬は上がる (最大2.0)\n",
    "            rewards = 1.0 - max_sim\n",
    "            \n",
    "        # 6. 記憶の更新 (現在のベクトルを記憶に追加)\n",
    "        self.memory_buffer = torch.cat([self.memory_buffer, current_vectors.detach()], dim=0)\n",
    "        \n",
    "        # 容量オーバーしたら古い記憶を捨てる (FIFO)\n",
    "        if self.memory_buffer.shape[0] > self.memory_capacity:\n",
    "            self.memory_buffer = self.memory_buffer[-self.memory_capacity:]\n",
    "            \n",
    "        return rewards\n",
    "\n",
    "    def clear_memory(self):\n",
    "        \"\"\"エピソードごとのリセット用\"\"\"\n",
    "        self.memory_buffer = torch.empty(0, self.basis.shape[1], device=self.device, dtype=self.dtype)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 4. 検証: 平凡 vs 多様 (時系列変化)\n",
    "# ==========================================\n",
    "print(\"\\n--- Step 2: Running Verification ---\")\n",
    "\n",
    "# IDCモデルの初期化\n",
    "idc_model = IDCRewardModel(basis_tensor, mean_tensor, DEVICE, memory_capacity=512)\n",
    "\n",
    "# テストケース\n",
    "test_cases = [\n",
    "    {\n",
    "        \"label\": \"Repetitive (Dejà Vu)\",\n",
    "        \"text\": \"The cat sat on the mat. The cat sat on the mat. The cat sat on the mat. The cat sat on the mat.\"\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Diverse (Diffusive)\",\n",
    "        \"text\": \"The cat sat on the mat. Suddenly, a spaceship landed in the garden. Aliens came out and started dancing tango.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for case in test_cases:\n",
    "    label = case[\"label\"]\n",
    "    text = case[\"text\"]\n",
    "    \n",
    "    print(f\"Processing: {label}\")\n",
    "    \n",
    "    # 記憶をリセット\n",
    "    idc_model.clear_memory()\n",
    "    \n",
    "    # 推論実行\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "    \n",
    "    # 隠れ状態シーケンス [Seq, Dim]\n",
    "    h_seq = outputs.hidden_states[-1].squeeze(0)\n",
    "    \n",
    "    # トークンごとの報酬を計算\n",
    "    step_rewards = []\n",
    "    tokens = [tokenizer.decode(t) for t in inputs.input_ids[0]]\n",
    "    \n",
    "    # シミュレーションループ (1トークンずつ生成・記憶更新したと仮定)\n",
    "    for t in range(h_seq.shape[0]):\n",
    "        h_t = h_seq[t].unsqueeze(0) # [1, Dim]\n",
    "        r_t = idc_model.compute_reward_and_update(h_t)\n",
    "        step_rewards.append(r_t.item())\n",
    "        \n",
    "    # プロット\n",
    "    plt.plot(step_rewards, marker='o', label=f\"{label} (Avg: {np.mean(step_rewards):.3f})\")\n",
    "\n",
    "# グラフ設定\n",
    "plt.title(\"IDC Reward Transition: Repetitive vs Diverse\")\n",
    "plt.xlabel(\"Token Step\")\n",
    "plt.ylabel(\"IDC Reward (1 - Max Similarity)\")\n",
    "plt.axhline(0, color='black', linewidth=0.5)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== 考察 ===\")\n",
    "print(\"Repetitive: グラフが右肩下がり（または低空飛行）になれば成功。過去の自分（記憶）と似ているため報酬が減衰する。\")\n",
    "print(\"Diverse   : グラフが高い値を維持、または新しい単語のタイミングでスパイクすれば成功。常に新しい意味空間へ移動している。\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
