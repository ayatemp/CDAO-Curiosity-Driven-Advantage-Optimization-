{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087ca743",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f261a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import textwrap\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import numpy as np\n",
    "\n",
    "# ==========================================\n",
    "# 1. Ë®≠ÂÆö\n",
    "# ==========================================\n",
    "BASE_MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "SUBSPACE_PATH = \"common_subspace.pt\"  # ‰ª•Ââç‰ΩúÊàê„Åó„Åü„Éï„Ç°„Ç§„É´\n",
    "SAVED_MODEL_PATH = \"./saved_models/run-research-hybrid-01\" # ‚òÖ„Åì„Åì„ÇíÂÆüÈöõ„ÅÆ‰øùÂ≠ò„Éë„Çπ„Å´Â§âÊõ¥ÔºÅ\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1b3e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. „Çπ„Ç≥„Ç¢Ë®àÁÆóÁî®„ÇØ„É©„Çπ (ÂÜçÊé≤)\n",
    "# ==========================================\n",
    "class ResidualCuriosityRewardModel(torch.nn.Module):\n",
    "    def __init__(self, path, device):\n",
    "        super().__init__()\n",
    "        data = torch.load(path, map_location=\"cpu\", weights_only=False)\n",
    "        self.register_buffer(\"basis\", data[\"basis\"].to(device, dtype=torch.float16))\n",
    "        self.register_buffer(\"mean\", data[\"mean\"].to(device, dtype=torch.float16))\n",
    "\n",
    "    def get_score(self, hidden_states):\n",
    "        \"\"\"Hidden States [Seq, D] „Åã„ÇâÂ•ΩÂ•áÂøÉ„Çπ„Ç≥„Ç¢„ÇíË®àÁÆó\"\"\"\n",
    "        h = hidden_states.to(self.basis.dtype)\n",
    "        h_centered = h - self.mean\n",
    "        z_common = h_centered @ self.basis.T\n",
    "        h_common = z_common @ self.basis\n",
    "        h_residual = h_centered - h_common\n",
    "        norms = torch.norm(h_residual, dim=-1)\n",
    "        return torch.log1p(norms).mean().item()\n",
    "\n",
    "# ==========================================\n",
    "# 3. Êé®Ë´ñ„ÉªÊØîËºÉÈñ¢Êï∞\n",
    "# ==========================================\n",
    "def compare_models(prompts):\n",
    "    print(f\"Loading Base Model: {BASE_MODEL_NAME} ...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)\n",
    "    \n",
    "    # „Éô„Éº„Çπ„É¢„Éá„É´„ÅÆ„É≠„Éº„Éâ\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        BASE_MODEL_NAME,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    \n",
    "    # Ë©ï‰æ°Âô®„ÅÆ„É≠„Éº„Éâ\n",
    "    scorer = ResidualCuriosityRewardModel(SUBSPACE_PATH, DEVICE)\n",
    "    \n",
    "    # --- 1. Base Model ÁîüÊàê ---\n",
    "    print(\"\\n>>> Generating with [BASE MODEL]...\")\n",
    "    base_results = generate(base_model, tokenizer, prompts, scorer)\n",
    "    \n",
    "    # --- 2. Trained Model ÁîüÊàê ---\n",
    "    print(f\"\\n>>> Loading Adapter from {SAVED_MODEL_PATH}...\")\n",
    "    # LoRA„Ç¢„ÉÄ„Éó„Çø„Éº„ÇíÂêà‰Ωì\n",
    "    trained_model = PeftModel.from_pretrained(base_model, SAVED_MODEL_PATH)\n",
    "    \n",
    "    print(\">>> Generating with [RDRL TRAINED MODEL]...\")\n",
    "    trained_results = generate(trained_model, tokenizer, prompts, scorer)\n",
    "    \n",
    "    # --- 3. ÁµêÊûúË°®Á§∫ ---\n",
    "    print_comparison(prompts, base_results, trained_results)\n",
    "\n",
    "def generate(model, tokenizer, prompts, scorer):\n",
    "    results = []\n",
    "    for prompt in prompts:\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=128,\n",
    "                do_sample=True,\n",
    "                temperature=0.9,\n",
    "                top_p=0.95,\n",
    "                repetition_penalty=1.1,\n",
    "                output_hidden_states=True,\n",
    "                return_dict_in_generate=True\n",
    "            )\n",
    "        \n",
    "        # „ÉÜ„Ç≠„Çπ„Éà\n",
    "        gen_text = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n",
    "        response = gen_text[len(prompt):]\n",
    "        \n",
    "        # „Çπ„Ç≥„Ç¢Ë®àÁÆó (ÁîüÊàêÈÉ®ÂàÜ„ÅÆHidden State„Çí‰ΩøÁî®)\n",
    "        # outputs.hidden_states: (step, layer, batch, 1, dim)\n",
    "        hidden_list = []\n",
    "        # „Éó„É≠„É≥„Éó„Éà‰ª•Èôç„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó„ÇíÂèñÂæó\n",
    "        start_idx = inputs.input_ids.shape[1] - 1\n",
    "        \n",
    "        # generate„ÅÆÊàª„ÇäÂÄ§ÊßãÈÄ†„Å´Âêà„Çè„Åõ„Å¶ÊäΩÂá∫\n",
    "        # (ÈÄöÂ∏∏„ÅØ tuple(steps) „Å™„ÅÆ„Åß„ÄÅ„Åù„Åì„Åã„ÇâÊúÄÁµÇÂ±§„ÇíÂèñ„ÇäÂá∫„Åô)\n",
    "        if len(outputs.hidden_states) > 1:\n",
    "            for step_data in outputs.hidden_states:\n",
    "                last_layer = step_data[-1].squeeze(0).squeeze(0)\n",
    "                hidden_list.append(last_layer)\n",
    "            \n",
    "            if hidden_list:\n",
    "                h_seq = torch.stack(hidden_list, dim=0)\n",
    "                score = scorer.get_score(h_seq)\n",
    "            else:\n",
    "                score = 0.0\n",
    "        else:\n",
    "            score = 0.0\n",
    "            \n",
    "        results.append({\"text\": response, \"score\": score})\n",
    "    return results\n",
    "\n",
    "def print_comparison(prompts, base_res, trained_res):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" CREATIVITY SHOWDOWN: Base vs RDRL\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    wins = 0\n",
    "    \n",
    "    for i, (p, b, t) in enumerate(zip(prompts, base_res, trained_res)):\n",
    "        print(f\"\\nPrompt {i+1}: {p.strip()}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Base\n",
    "        print(f\"[Base Model] (Score: {b['score']:.4f})\")\n",
    "        print(textwrap.fill(b['text'].strip(), width=80))\n",
    "        print(\"-\" * 20)\n",
    "        \n",
    "        # Trained\n",
    "        print(f\"[RDRL Model] (Score: {t['score']:.4f})\")\n",
    "        print(textwrap.fill(t['text'].strip(), width=80))\n",
    "        print(\"-\" * 20)\n",
    "        \n",
    "        # Âà§ÂÆö\n",
    "        diff = t['score'] - b['score']\n",
    "        if diff > 0:\n",
    "            print(f\"üèÜ WINNER: RDRL Model (+{diff:.4f})\")\n",
    "            wins += 1\n",
    "        else:\n",
    "            print(f\"üëæ WINNER: Base Model ({diff:.4f})\")\n",
    "            \n",
    "    print(\"=\"*80)\n",
    "    print(f\"Final Result: RDRL Model won {wins} / {len(prompts)} rounds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fa2216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4. „ÉÜ„Çπ„ÉàÁî®„Éó„É≠„É≥„Éó„Éà (Á†îÁ©∂„Ç¢„Ç§„Éá„Ç¢)\n",
    "# ==========================================\n",
    "test_prompts = [\n",
    "    \"\"\"You are an expert LLM researcher. Propose a novel and concrete research idea about large language models.\n",
    "Output ONLY in the following format:\n",
    "Title: <concise LLM research title>\n",
    "Abstract: <150-220 word abstract>\n",
    "Draft a research proposal about Mixture of Experts (MoE).\"\"\",\n",
    "    \n",
    "    \"\"\"You are an expert LLM researcher. Propose a novel and concrete research idea about large language models.\n",
    "Output ONLY in the following format:\n",
    "Title: <concise LLM research title>\n",
    "Abstract: <150-220 word abstract>\n",
    "Propose an experiment improving Hallucination Detection with a focus on interpretability.\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models(test_prompts)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
