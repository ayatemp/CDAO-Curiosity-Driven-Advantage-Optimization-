{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c73cbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807732ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbc7649",
   "metadata": {},
   "source": [
    "# データ読み取り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965319ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"data/df_full.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c3bc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130179fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c472724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489e49ca",
   "metadata": {},
   "source": [
    "# 解析用配列を抜き出す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cd3d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stories = df_full.dropna(subset=[\"creativity_score\"]).reset_index(drop=True)\n",
    "print(\"有効サンプル数:\", len(df_stories))\n",
    "\n",
    "# EOS 埋め込みと生成平均埋め込みの列名を取得\n",
    "eos_cols = [c for c in df_stories.columns if c.startswith(\"eos_dim_\")]\n",
    "gen_cols = [c for c in df_stories.columns if c.startswith(\"gen_dim_\")]\n",
    "\n",
    "print(\"EOS 次元数:\", len(eos_cols))\n",
    "print(\"GEN 次元数:\", len(gen_cols))\n",
    "\n",
    "# 行列化\n",
    "X_eos = df_stories[eos_cols].to_numpy(dtype=np.float32)   # [N, hidden_dim]\n",
    "X_gen = df_stories[gen_cols].to_numpy(dtype=np.float32)   # [N, hidden_dim]\n",
    "\n",
    "# 目的変数（スコア類）\n",
    "y_scores      = df_stories[\"creativity_score\"].astype(np.float32).to_numpy()\n",
    "creativity    = df_stories[\"creativity\"].astype(np.float32).to_numpy()\n",
    "originality   = df_stories[\"originality\"].astype(np.float32).to_numpy()\n",
    "coherence     = df_stories[\"coherence\"].astype(np.float32).to_numpy()\n",
    "\n",
    "print(\"X_eos shape:\", X_eos.shape)\n",
    "print(\"X_gen shape:\", X_gen.shape)\n",
    "print(\"y_scores shape:\", y_scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094dde4e",
   "metadata": {},
   "source": [
    "# EOS 埋め込みで creative_direction を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1551d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_thresh = np.quantile(y_scores, 0.7)\n",
    "low_thresh  = np.quantile(y_scores, 0.3)\n",
    "\n",
    "mask_high = y_scores >= high_thresh\n",
    "mask_low  = y_scores <= low_thresh\n",
    "\n",
    "X_high = X_eos[mask_high]\n",
    "X_low  = X_eos[mask_low]\n",
    "\n",
    "print(\"X_high (EOS) shape:\", X_high.shape)\n",
    "print(\"X_low  (EOS) shape:\", X_low.shape)\n",
    "\n",
    "# 2) High/Low の平均差分ベクトル = creative_direction\n",
    "mu_high = X_high.mean(axis=0)\n",
    "mu_low  = X_low.mean(axis=0)\n",
    "\n",
    "creative_direction_eos = mu_high - mu_low\n",
    "creative_direction_eos = creative_direction_eos / np.linalg.norm(creative_direction_eos)\n",
    "\n",
    "# 3) full データで projection とスコアの相関\n",
    "proj_eos = X_eos @ creative_direction_eos  # [N]\n",
    "\n",
    "corr_full = np.corrcoef(proj_eos, y_scores)[0, 1]\n",
    "print(\"=== EOS direction: full データでの創造性スコアとの相関 ===\")\n",
    "print(\"corr(full):\", corr_full)\n",
    "\n",
    "# 4) train / test split で汎化を見る\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_eos, y_scores, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "high_th = np.quantile(y_train, 0.7)\n",
    "low_th  = np.quantile(y_train, 0.3)\n",
    "\n",
    "mask_train_high = y_train >= high_th\n",
    "mask_train_low  = y_train <= low_th\n",
    "\n",
    "Xh = X_train[mask_train_high]\n",
    "Xl = X_train[mask_train_low]\n",
    "\n",
    "print(\"train High (EOS) shape:\", Xh.shape)\n",
    "print(\"train Low  (EOS) shape:\", Xl.shape)\n",
    "\n",
    "mu_h = Xh.mean(axis=0)\n",
    "mu_l = Xl.mean(axis=0)\n",
    "\n",
    "cd_eos = mu_h - mu_l\n",
    "cd_eos = cd_eos / np.linalg.norm(cd_eos)\n",
    "\n",
    "proj_test = X_test @ cd_eos\n",
    "corr_test = np.corrcoef(proj_test, y_test)[0, 1]\n",
    "\n",
    "print(\"=== EOS direction: test データでの創造性スコアとの相関 ===\")\n",
    "print(\"corr(test):\", corr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ca2d42",
   "metadata": {},
   "source": [
    "# 生成部分平均埋め込みで creative_direction & 相関"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1de312",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_thresh_gen = np.quantile(y_scores, 0.7)\n",
    "low_thresh_gen  = np.quantile(y_scores, 0.3)\n",
    "\n",
    "mask_high_gen = y_scores >= high_thresh_gen\n",
    "mask_low_gen  = y_scores <= low_thresh_gen\n",
    "\n",
    "X_high_gen = X_gen[mask_high_gen]\n",
    "X_low_gen  = X_gen[mask_low_gen]\n",
    "\n",
    "print(\"X_high (GEN) shape:\", X_high_gen.shape)\n",
    "print(\"X_low  (GEN) shape:\", X_low_gen.shape)\n",
    "\n",
    "mu_high_gen = X_high_gen.mean(axis=0)\n",
    "mu_low_gen  = X_low_gen.mean(axis=0)\n",
    "\n",
    "creative_direction_gen = mu_high_gen - mu_low_gen\n",
    "creative_direction_gen = creative_direction_gen / np.linalg.norm(creative_direction_gen)\n",
    "\n",
    "proj_gen = X_gen @ creative_direction_gen\n",
    "\n",
    "corr_full_gen = np.corrcoef(proj_gen, y_scores)[0, 1]\n",
    "print(\"=== GEN-mean direction: full データでの創造性スコアとの相関 ===\")\n",
    "print(\"corr(full):\", corr_full_gen)\n",
    "\n",
    "# 2) train / test split\n",
    "X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(\n",
    "    X_gen, y_scores, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "high_th_g = np.quantile(y_train_g, 0.7)\n",
    "low_th_g  = np.quantile(y_train_g, 0.3)\n",
    "\n",
    "mask_train_high_g = y_train_g >= high_th_g\n",
    "mask_train_low_g  = y_train_g <= low_th_g\n",
    "\n",
    "Xh_g = X_train_g[mask_train_high_g]\n",
    "Xl_g = X_train_g[mask_train_low_g]\n",
    "\n",
    "mu_h_g = Xh_g.mean(axis=0)\n",
    "mu_l_g = Xl_g.mean(axis=0)\n",
    "\n",
    "cd_gen = mu_h_g - mu_l_g\n",
    "cd_gen = cd_gen / np.linalg.norm(cd_gen)\n",
    "\n",
    "proj_test_g = X_test_g @ cd_gen\n",
    "corr_test_g = np.corrcoef(proj_test_g, y_test_g)[0, 1]\n",
    "\n",
    "print(\"=== GEN-mean direction: test データでの創造性スコアとの相関 ===\")\n",
    "print(\"corr(test):\", corr_test_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df62cac",
   "metadata": {},
   "source": [
    "# Projection × 各スコアの相関（EOS direction）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ed8fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(a, b):\n",
    "    return np.corrcoef(a, b)[0, 1]\n",
    "\n",
    "# NaN を一応除外（ほぼ無いはずだが保険）\n",
    "mask_valid = (\n",
    "    np.isfinite(proj_eos)\n",
    "    & np.isfinite(creativity)\n",
    "    & np.isfinite(originality)\n",
    "    & np.isfinite(coherence)\n",
    "    & np.isfinite(y_scores)\n",
    ")\n",
    "\n",
    "proj_valid             = proj_eos[mask_valid]\n",
    "creativity_valid       = creativity[mask_valid]\n",
    "originality_valid      = originality[mask_valid]\n",
    "coherence_valid        = coherence[mask_valid]\n",
    "creativity_score_valid = y_scores[mask_valid]\n",
    "\n",
    "print(\"===== Projection (EOS direction) × 各スコアの相関 =====\")\n",
    "print(f\"creativity          : {corr(proj_valid, creativity_valid):.4f}\")\n",
    "print(f\"originality         : {corr(proj_valid, originality_valid):.4f}\")\n",
    "print(f\"coherence           : {corr(proj_valid, coherence_valid):.4f}\")\n",
    "print(f\"creativity_score(*) : {corr(proj_valid, creativity_score_valid):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eafe332",
   "metadata": {},
   "source": [
    "# スコアの基本統計量 & 分布ヒストグラム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf84f9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_stories[[\"creativity\", \"originality\", \"coherence\", \"creativity_score\"]].describe())\n",
    "\n",
    "for col in [\"creativity\", \"originality\", \"coherence\", \"creativity_score\"]:\n",
    "    plt.figure()\n",
    "    df_stories[col].hist(bins=10)\n",
    "    plt.title(col)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7ae2eb",
   "metadata": {},
   "source": [
    "# 各層の「生成部分平均 hidden」を全部集める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053a8b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_for_layers = df_full[\"prompt\"].tolist()          # df_full と同じ順序のプロンプト\n",
    "y_scores = df_full[\"creativity_score\"].to_numpy(dtype=np.float32)  # ラベル\n",
    "\n",
    "all_gen_layers = []  # shape: [N, num_layers_plus1, hidden_dim]\n",
    "\n",
    "for prompt in tqdm(prompts_for_layers, desc=\"Collect per-layer gen-mean features\"):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=300,\n",
    "            temperature=1.0,\n",
    "            do_sample=True,\n",
    "            output_hidden_states=True,\n",
    "            return_dict_in_generate=True,\n",
    "        )\n",
    "\n",
    "    # 1ステップごとの hidden_states のうち「最後のステップ」を取り出す\n",
    "    # last_step_hiddens: tuple of length = num_layers + 1\n",
    "    #   各要素: [batch=1, seq_len, hidden_dim]\n",
    "    last_step_hiddens = out.hidden_states[-1]\n",
    "\n",
    "    # 入力長・生成長計算\n",
    "    input_len = inputs[\"input_ids\"].shape[1]\n",
    "    # 最終層の hidden から seq_len を取る（どの層でも同じ長さ）\n",
    "    final_layer_hidden = last_step_hiddens[-1]\n",
    "    seq_len = final_layer_hidden.shape[1]\n",
    "    gen_len = max(1, seq_len - input_len)\n",
    "\n",
    "    layer_gen_vecs = []\n",
    "    for layer_hidden in last_step_hiddens:\n",
    "        # 各層の「生成部分だけ」の平均ベクトルを計算\n",
    "        # layer_hidden: [1, seq_len, hidden_dim]\n",
    "        gen_hidden = layer_hidden[0, -gen_len:, :]          # [gen_len, hidden_dim]\n",
    "        gen_mean = gen_hidden.mean(dim=0)                   # [hidden_dim]\n",
    "        layer_gen_vecs.append(gen_mean.to(torch.float32).cpu().numpy())\n",
    "\n",
    "    # (num_layers+1, hidden_dim) にまとめる\n",
    "    layer_gen_mat = np.stack(layer_gen_vecs, axis=0)\n",
    "    all_gen_layers.append(layer_gen_mat)\n",
    "\n",
    "# (N, num_layers+1, hidden_dim)\n",
    "all_gen_layers = np.stack(all_gen_layers, axis=0)\n",
    "\n",
    "print(\"all_gen_layers shape:\", all_gen_layers.shape)\n",
    "# 例: (N, 29, 3584) みたいな形（28層 + 最終norm の 29 \"層\"）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34357771",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, L, D = all_gen_layers.shape\n",
    "\n",
    "# (N, L*D) に reshape\n",
    "flat = all_gen_layers.reshape(N, L * D)\n",
    "\n",
    "# カラム名を作成\n",
    "columns = [f\"layer{layer}_dim{dim}\" for layer in range(L) for dim in range(D)]\n",
    "\n",
    "df_layers = pd.DataFrame(flat, columns=columns)\n",
    "\n",
    "df_layers.to_csv(\"data/all_gen_layers_flat.csv\", index=False)\n",
    "print(\"Saved to all_gen_layers_flat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4257de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import re\n",
    "\n",
    "# # === CSV 読み込み ===\n",
    "# df = pd.read_csv(\"all_gen_layers_flat.csv\")\n",
    "\n",
    "# # === 層と次元の数を自動判定 ===\n",
    "# layer_dim_pattern = r\"layer(\\d+)_dim(\\d+)\"\n",
    "# layers = []\n",
    "# dims = []\n",
    "\n",
    "# for col in df.columns:\n",
    "#     m = re.match(layer_dim_pattern, col)\n",
    "#     if m:\n",
    "#         layers.append(int(m.group(1)))\n",
    "#         dims.append(int(m.group(2)))\n",
    "\n",
    "# L = max(layers) + 1\n",
    "# D = max(dims) + 1\n",
    "# N = len(df)\n",
    "\n",
    "# print(f\"Detected shape: N={N}, L={L}, D={D}\")\n",
    "\n",
    "# # === numpy 配列に変換 ===\n",
    "# arr = df.to_numpy(dtype=np.float32)\n",
    "\n",
    "# # === (N, L, D) に reshape ===\n",
    "# all_gen_layers = arr.reshape(N, L, D)\n",
    "\n",
    "# print(\"all_gen_layers shape:\", all_gen_layers.shape)\n",
    "# print(\"復元完了！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb259487",
   "metadata": {},
   "source": [
    "# 各層ごとに creative_direction と相関を計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a93b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, L, D = all_gen_layers.shape  # N=サンプル数, L=層数(+final), D=hidden_dim\n",
    "\n",
    "# 上位・下位 30% で High / Low を定義\n",
    "high_thresh = np.quantile(y_scores, 0.7)\n",
    "low_thresh  = np.quantile(y_scores, 0.3)\n",
    "\n",
    "mask_high = y_scores >= high_thresh\n",
    "mask_low  = y_scores <= low_thresh\n",
    "\n",
    "results = []\n",
    "\n",
    "for layer_idx in range(L):\n",
    "    X_layer = all_gen_layers[:, layer_idx, :]  # [N, hidden_dim]\n",
    "\n",
    "    X_high = X_layer[mask_high]\n",
    "    X_low  = X_layer[mask_low]\n",
    "\n",
    "    if len(X_high) == 0 or len(X_low) == 0:\n",
    "        results.append({\"layer_idx\": layer_idx, \"corr_full\": np.nan})\n",
    "        continue\n",
    "\n",
    "    # High / Low の平均差分ベクトル\n",
    "    mu_high = X_high.mean(axis=0)\n",
    "    mu_low  = X_low.mean(axis=0)\n",
    "\n",
    "    w = mu_high - mu_low\n",
    "    norm = np.linalg.norm(w)\n",
    "    if norm < 1e-8:\n",
    "        results.append({\"layer_idx\": layer_idx, \"corr_full\": np.nan})\n",
    "        continue\n",
    "    w = w / norm\n",
    "\n",
    "    # 各サンプルの projection\n",
    "    proj = X_layer @ w\n",
    "\n",
    "    # creativity_score との相関\n",
    "    corr = np.corrcoef(proj, y_scores)[0, 1]\n",
    "\n",
    "    results.append({\n",
    "        \"layer_idx\": layer_idx,\n",
    "        \"corr_full\": corr,\n",
    "    })\n",
    "\n",
    "df_layers = pd.DataFrame(results)\n",
    "print(\"各層ごとの creative_direction × creativity_score の相関:\")\n",
    "display(df_layers.sort_values(\"corr_full\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6028e368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NaN は除いておく\n",
    "vals = df_layers[\"corr_full\"].dropna()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(df_layers[\"layer_idx\"], df_layers[\"corr_full\"])\n",
    "plt.xlabel(\"layer_idx\")\n",
    "plt.ylabel(\"corr_full\")\n",
    "plt.title(\"corr_full by layer\")\n",
    "plt.axhline(0, linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be252cfc",
   "metadata": {},
   "source": [
    "# 一番相関が高い層で「どの次元が効いているか」を見る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7802a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相関が最大の layer_idx を取る\n",
    "best_row = df_layers.iloc[df_layers[\"corr_full\"].idxmax()]\n",
    "best_layer_idx = int(best_row[\"layer_idx\"])\n",
    "print(\"相関最大の layer_idx:\", best_layer_idx, \" corr:\", best_row[\"corr_full\"])\n",
    "\n",
    "X_layer = all_gen_layers[:, best_layer_idx, :]  # [N, hidden_dim]\n",
    "\n",
    "# High / Low を改めて作り直し\n",
    "high_thresh = np.quantile(y_scores, 0.7)\n",
    "low_thresh  = np.quantile(y_scores, 0.3)\n",
    "\n",
    "mask_high = y_scores >= high_thresh\n",
    "mask_low  = y_scores <= low_thresh\n",
    "\n",
    "X_high = X_layer[mask_high]\n",
    "X_low  = X_layer[mask_low]\n",
    "\n",
    "mu_high = X_high.mean(axis=0)\n",
    "mu_low  = X_low.mean(axis=0)\n",
    "\n",
    "w = mu_high - mu_low\n",
    "w = w / (np.linalg.norm(w) + 1e-8)\n",
    "\n",
    "# 絶対値が大きい次元トップKを表示\n",
    "K = 20\n",
    "top_idx = np.argsort(np.abs(w))[::-1][:K]\n",
    "\n",
    "print(f\"\\nlayer {best_layer_idx} の creative_direction で寄与の大きい次元 Top-{K}:\")\n",
    "for rank, dim_idx in enumerate(top_idx, start=1):\n",
    "    print(f\"#{rank:2d}  dim={dim_idx:4d}  weight={w[dim_idx]: .6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480ac5f4",
   "metadata": {},
   "source": [
    "# f(x)の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1bbe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# =========================================================\n",
    "# 0. 前提：all_gen_layers, y_scores がすでにあるとする\n",
    "#    all_gen_layers: (N, num_layers_plus1, hidden_dim)\n",
    "#    y_scores      : (N,)\n",
    "# =========================================================\n",
    "\n",
    "print(\"all_gen_layers shape:\", all_gen_layers.shape)\n",
    "print(\"y_scores shape      :\", y_scores.shape)\n",
    "\n",
    "N, num_layers_plus1, hidden_dim = all_gen_layers.shape\n",
    "\n",
    "# =========================================================\n",
    "# 1. どの層を対象にするか決める\n",
    "#    ここでは「中間層」を例として選ぶ（適宜変えてOK）\n",
    "# =========================================================\n",
    "# 例: 中間層\n",
    "layer_idx = num_layers_plus1 // 2\n",
    "# 例: 最終層を使いたければ layer_idx = num_layers_plus1 - 1\n",
    "\n",
    "print(f\"Using layer index: {layer_idx}\")\n",
    "\n",
    "# (N, hidden_dim) を取り出す\n",
    "X_layer = all_gen_layers[:, layer_idx, :]   # shape: (N, hidden_dim)\n",
    "y = y_scores.astype(np.float32)\n",
    "\n",
    "print(\"X_layer shape:\", X_layer.shape)\n",
    "\n",
    "# =========================================================\n",
    "# 2. train / test に分割\n",
    "# =========================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_layer, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 3. 特徴量を標準化（Lasso の安定性向上のため）\n",
    "# =========================================================\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std  = scaler.transform(X_test)\n",
    "\n",
    "# =========================================================\n",
    "# 4. L1 正則化付き線形回帰（LassoCV = α を自動チューニング）\n",
    "#    k-sparse linear probe の「簡易版」として使う\n",
    "# =========================================================\n",
    "lasso = LassoCV(\n",
    "    alphas=None,      # 自動で候補を作る\n",
    "    cv=5,             # 5-fold CV\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "lasso.fit(X_train_std, y_train)\n",
    "\n",
    "print(\"Lasso best alpha:\", lasso.alpha_)\n",
    "print(\"Train R^2:\", lasso.score(X_train_std, y_train))\n",
    "print(\"Test  R^2:\", lasso.score(X_test_std,  y_test))\n",
    "\n",
    "# =========================================================\n",
    "# 5. どのニューロン（次元）が重要かを見る\n",
    "# =========================================================\n",
    "coef = lasso.coef_      # shape: (hidden_dim,)\n",
    "abs_coef = np.abs(coef)\n",
    "\n",
    "# 非ゼロのニューロン数\n",
    "nonzero_idx = np.where(abs_coef > 0)[0]\n",
    "print(\"Number of non-zero neurons:\", len(nonzero_idx))\n",
    "\n",
    "# 上位 k 個を「創造性ニューロン」として見る\n",
    "k = 50  # 好きな数に調整\n",
    "topk_idx = np.argsort(-abs_coef)[:k]\n",
    "\n",
    "print(f\"Top-{k} important neuron indices (in this layer):\")\n",
    "print(topk_idx)\n",
    "\n",
    "print(\"Their coefficients (w):\")\n",
    "print(coef[topk_idx])\n",
    "\n",
    "# =========================================================\n",
    "# 6. 内部報酬として使うときの関数イメージ\n",
    "# =========================================================\n",
    "def creativity_internal_reward(h_layer: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    h_layer: shape (hidden_dim,) のベクトル\n",
    "             （この layer_idx の hidden）\n",
    "    返り値: 内部 creativity 報酬（スカラー）\n",
    "    \"\"\"\n",
    "    # スケーラーで標準化\n",
    "    h_std = scaler.transform(h_layer.reshape(1, -1))  # (1, hidden_dim)\n",
    "    # Lasso の線形予測 = GPT-4 creativity の近似\n",
    "    reward = float(lasso.predict(h_std)[0])\n",
    "    return reward\n",
    "\n",
    "# 例: テストデータの1サンプルで試す\n",
    "sample_h = X_test[0]   # shape: (hidden_dim,)\n",
    "sample_y = y_test[0]\n",
    "sample_reward = creativity_internal_reward(sample_h)\n",
    "print(\"Sample true score (GPT-4):\", sample_y)\n",
    "print(\"Sample internal reward   :\", sample_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230d1624",
   "metadata": {},
   "source": [
    "# 報酬関数の具体的な検討案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424469f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# ==========================================\n",
    "# 0. 前処理：基本情報の取得\n",
    "# ==========================================\n",
    "\n",
    "# df_full と all_gen_layers が既にある前提\n",
    "# df_full: pandas.DataFrame\n",
    "# all_gen_layers: np.ndarray, shape (N, num_layers, hidden_dim)\n",
    "\n",
    "assert \"creativity_score\" in df_full.columns, \"df_full に 'creativity_score' カラムが必要です\"\n",
    "\n",
    "y = df_full[\"creativity_score\"].to_numpy(dtype=np.float32)  # shape (N,)\n",
    "N, num_layers, hidden_dim = all_gen_layers.shape\n",
    "print(\"N, num_layers, hidden_dim:\", N, num_layers, hidden_dim)\n",
    "\n",
    "# 相関を計算する小ヘルパー\n",
    "def corr(a, b):\n",
    "    return float(np.corrcoef(a, b)[0, 1])\n",
    "\n",
    "# ==========================================\n",
    "# 1. Method1: 層ごとの creative_direction を重み付き合成した報酬\n",
    "#    r_int1[i] = Σ_l w_l * <h_i^(l), d^(l)>\n",
    "# ==========================================\n",
    "\n",
    "creative_dirs = np.zeros((num_layers, hidden_dim), dtype=np.float32)  # d^(l)\n",
    "layer_proj = np.zeros((N, num_layers), dtype=np.float32)              # 各層の投影値\n",
    "layer_corrs = np.zeros(num_layers, dtype=np.float32)\n",
    "\n",
    "# high/low の分位点は全層共通でOK\n",
    "high_th = np.quantile(y, 0.7)\n",
    "low_th  = np.quantile(y, 0.3)\n",
    "mask_high = y >= high_th\n",
    "mask_low  = y <= low_th\n",
    "\n",
    "for l in range(num_layers):\n",
    "    X_l = all_gen_layers[:, l, :]   # (N, hidden_dim)\n",
    "\n",
    "    # high / low の平均差分方向\n",
    "    mu_high = X_l[mask_high].mean(axis=0)\n",
    "    mu_low  = X_l[mask_low].mean(axis=0)\n",
    "    d_l = mu_high - mu_low\n",
    "    norm = np.linalg.norm(d_l) + 1e-8\n",
    "    d_l = d_l / norm\n",
    "\n",
    "    creative_dirs[l] = d_l\n",
    "\n",
    "    # 各サンプル i の投影値: proj_i = <h_i^(l), d_l>\n",
    "    proj_l = X_l @ d_l  # (N,)\n",
    "    layer_proj[:, l] = proj_l\n",
    "\n",
    "    # 層ごとの相関\n",
    "    layer_corrs[l] = corr(proj_l, y)\n",
    "\n",
    "print(\"=== Method1: 層ごとの相関 ===\")\n",
    "for l in range(num_layers):\n",
    "    print(f\"layer {l:2d}: corr = {layer_corrs[l]:.4f}\")\n",
    "\n",
    "# 負の相関は切り捨てて、正の層だけ重みとして使う方が無難\n",
    "w = np.maximum(layer_corrs, 0.0)\n",
    "if w.sum() > 0:\n",
    "    w = w / w.sum()\n",
    "else:\n",
    "    # 全部 <=0 の場合は絶対値で正規化\n",
    "    w = np.abs(layer_corrs)\n",
    "    w = w / (w.sum() + 1e-8)\n",
    "\n",
    "print(\"Method1: 重み w（先頭10個）:\", w[:10])\n",
    "\n",
    "# サンプルごとの aggregated reward\n",
    "reward_dir_agg = (layer_proj * w[None, :]).sum(axis=1)  # (N,)\n",
    "\n",
    "df_full[\"reward_dir_agg\"] = reward_dir_agg\n",
    "print(\"Method1: corr(reward_dir_agg, creativity_score) =\",\n",
    "      corr(reward_dir_agg, y))\n",
    "\n",
    "# ==========================================\n",
    "# 2. Method2: 全層フラット + PLSRegression による\n",
    "#    グローバル創造性方向（dense）\n",
    "#    r_int2[i] = PLS(X_flat[i])（標準化済み）\n",
    "# ==========================================\n",
    "\n",
    "# (N, num_layers * hidden_dim) にフラット化\n",
    "X_flat = all_gen_layers.reshape(N, num_layers * hidden_dim)\n",
    "\n",
    "# 特徴量・ターゲットの標準化\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X_flat)  # (N, D)\n",
    "\n",
    "y_2d = y.reshape(-1, 1)\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y_2d).ravel()  # 平均0, 分散1\n",
    "\n",
    "# PLSRegression で n_components=1\n",
    "pls = PLSRegression(n_components=1)\n",
    "pls.fit(X_scaled, y_scaled)\n",
    "\n",
    "y_pred_pls = pls.predict(X_scaled).ravel()  # (N,)\n",
    "\n",
    "df_full[\"reward_pls_global\"] = y_pred_pls\n",
    "\n",
    "print(\"Method2: PLSRegression\")\n",
    "print(\"  corr(y_pred_pls, creativity_score)        =\", corr(y_pred_pls, y))\n",
    "print(\"  corr(y_pred_pls, y_scaled) (形のチェック) =\", corr(y_pred_pls, y_scaled))\n",
    "\n",
    "# ==========================================\n",
    "# 3. Method3: 全層フラット + LassoCV による\n",
    "#    グローバル sparse linear probe\n",
    "#    r_int3[i] = Lasso(X_scaled[i])\n",
    "# ==========================================\n",
    "\n",
    "lasso = LassoCV(\n",
    "    alphas=None,     # 自動\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "lasso.fit(X_scaled, y_scaled)\n",
    "\n",
    "y_pred_lasso = lasso.predict(X_scaled)  # (N,)\n",
    "\n",
    "df_full[\"reward_lasso_global\"] = y_pred_lasso\n",
    "\n",
    "num_nonzero = np.sum(lasso.coef_ != 0)\n",
    "print(\"Method3: LassoCV\")\n",
    "print(\"  best alpha:\", lasso.alpha_)\n",
    "print(\"  non-zero features:\", num_nonzero, \"/\", lasso.coef_.shape[0])\n",
    "print(\"  corr(y_pred_lasso, creativity_score)        =\", corr(y_pred_lasso, y))\n",
    "print(\"  corr(y_pred_lasso, y_scaled) (形のチェック) =\", corr(y_pred_lasso, y_scaled))\n",
    "\n",
    "# ==========================================\n",
    "# 4. 結果のざっくりサマリ\n",
    "# ==========================================\n",
    "print(\"\\n=== Summary ===\")\n",
    "print(\"Method1 (layer-wise dir agg)   corr =\", corr(df_full[\"reward_dir_agg\"], y))\n",
    "print(\"Method2 (PLS global direction) corr =\", corr(df_full[\"reward_pls_global\"], y))\n",
    "print(\"Method3 (Lasso sparse global)  corr =\", corr(df_full[\"reward_lasso_global\"], y))\n",
    "\n",
    "# 必要なら df_full.to_csv(\"df_with_internal_rewards.csv\", index=False) などで保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be3c13",
   "metadata": {},
   "source": [
    "# Lasso RM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510b5a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# ==========================================\n",
    "# 0. 前提チェック\n",
    "# ==========================================\n",
    "\n",
    "assert \"creativity_score\" in df_full.columns, \"df_full に 'creativity_score' カラムが必要です\"\n",
    "assert isinstance(all_gen_layers, np.ndarray), \"all_gen_layers は np.ndarray である必要があります\"\n",
    "\n",
    "N, num_layers, hidden_dim = all_gen_layers.shape\n",
    "print(f\"N={N}, num_layers={num_layers}, hidden_dim={hidden_dim}\")\n",
    "\n",
    "# 目的変数\n",
    "y = df_full[\"creativity_score\"].to_numpy(dtype=np.float32)  # shape (N,)\n",
    "\n",
    "# ヘルパー：相関\n",
    "def corr(a, b):\n",
    "    return float(np.corrcoef(a, b)[0, 1])\n",
    "\n",
    "# ==========================================\n",
    "# 1. 特徴量フラット化\n",
    "#    all_gen_layers: (N, L, D) → X: (N, L*D)\n",
    "# ==========================================\n",
    "\n",
    "X = all_gen_layers.reshape(N, num_layers * hidden_dim)  # (N, D_flat)\n",
    "print(\"X shape:\", X.shape)\n",
    "\n",
    "# ==========================================\n",
    "# 2. train/test 分割（インデックスも保存）\n",
    "# ==========================================\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "indices = np.arange(N)\n",
    "idx_train, idx_test = train_test_split(\n",
    "    indices,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "X_train = X[idx_train]\n",
    "X_test  = X[idx_test]\n",
    "y_train = y[idx_train]\n",
    "y_test  = y[idx_test]\n",
    "\n",
    "print(\"Train size:\", X_train.shape[0], \" Test size:\", X_test.shape[0])\n",
    "\n",
    "# ==========================================\n",
    "# 3. 標準化（X, y ともに train のみで fit）\n",
    "# ==========================================\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "X_train_std = scaler_X.fit_transform(X_train)\n",
    "X_test_std  = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_train_std = scaler_y.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
    "\n",
    "# ==========================================\n",
    "# 4. LassoCV の学習（sparse global RM）\n",
    "# ==========================================\n",
    "\n",
    "lasso = LassoCV(\n",
    "    alphas=None,      # 自動選択\n",
    "    cv=5,             # 5-fold CV\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    max_iter=5000,\n",
    ")\n",
    "\n",
    "lasso.fit(X_train_std, y_train_std)\n",
    "\n",
    "print(\"\\n=== LassoCV fit done ===\")\n",
    "print(\"best alpha:\", lasso.alpha_)\n",
    "\n",
    "# ==========================================\n",
    "# 5. train/test の予測 & 元スケールへの逆変換\n",
    "# ==========================================\n",
    "\n",
    "y_train_pred_std = lasso.predict(X_train_std)         # 標準化空間\n",
    "y_test_pred_std  = lasso.predict(X_test_std)\n",
    "\n",
    "# 元スケールへ戻す\n",
    "y_train_pred = scaler_y.inverse_transform(\n",
    "    y_train_pred_std.reshape(-1, 1)\n",
    ").ravel()\n",
    "y_test_pred = scaler_y.inverse_transform(\n",
    "    y_test_pred_std.reshape(-1, 1)\n",
    ").ravel()\n",
    "\n",
    "# ==========================================\n",
    "# 6. 評価指標の計算\n",
    "# ==========================================\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "metrics[\"corr_train\"] = corr(y_train_pred, y_train)\n",
    "metrics[\"corr_test\"]  = corr(y_test_pred,  y_test)\n",
    "\n",
    "metrics[\"r2_train\"] = r2_score(y_train, y_train_pred)\n",
    "metrics[\"r2_test\"]  = r2_score(y_test,  y_test_pred)\n",
    "\n",
    "metrics[\"mae_train\"] = mean_absolute_error(y_train, y_train_pred)\n",
    "metrics[\"mae_test\"]  = mean_absolute_error(y_test,  y_test_pred)\n",
    "\n",
    "metrics[\"rmse_train\"] = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "metrics[\"rmse_test\"]  = np.sqrt(mean_squared_error(y_test,  y_test_pred))\n",
    "print(\"\\n=== Evaluation (Lasso global RM) ===\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k:>10}: {v:.4f}\")\n",
    "\n",
    "# ==========================================\n",
    "# 7. 予測を df_full に格納（rm_lasso_pred 列）\n",
    "#    インデックスを対応させる\n",
    "# ==========================================\n",
    "\n",
    "df_full = df_full.copy()  # もともとの df_full を壊さないようにコピー\n",
    "\n",
    "df_full[\"rm_lasso_pred\"] = np.nan\n",
    "df_full.loc[idx_train, \"rm_lasso_pred\"] = y_train_pred\n",
    "df_full.loc[idx_test,  \"rm_lasso_pred\"] = y_test_pred\n",
    "\n",
    "print(\"\\nSample of df_full[['creativity_score', 'rm_lasso_pred']]:\")\n",
    "print(df_full[[\"creativity_score\", \"rm_lasso_pred\"]].head())\n",
    "\n",
    "# ==========================================\n",
    "# 8. スパース性の解析（どの層のどの次元が効いているか）\n",
    "# ==========================================\n",
    "\n",
    "coef = lasso.coef_  # shape: (num_layers * hidden_dim,)\n",
    "\n",
    "nonzero_idx = np.where(coef != 0)[0]\n",
    "num_nonzero = nonzero_idx.shape[0]\n",
    "\n",
    "print(\"\\n=== Sparsity info ===\")\n",
    "print(\"non-zero features:\", num_nonzero, \"/\", coef.size)\n",
    "\n",
    "# 層ごとの non-zero 数をカウント\n",
    "layer_counts = {}\n",
    "for k in nonzero_idx:\n",
    "    layer = k // hidden_dim\n",
    "    dim   = k % hidden_dim\n",
    "    layer_counts[layer] = layer_counts.get(layer, 0) + 1\n",
    "\n",
    "print(\"non-zero coeff per layer (layer: count):\")\n",
    "for l in sorted(layer_counts.keys()):\n",
    "    print(f\"  layer {l:2d}: {layer_counts[l]}\")\n",
    "\n",
    "# 重要度上位を見たい場合（任意）\n",
    "top_k = 20\n",
    "abs_coef = np.abs(coef)\n",
    "top_idx = np.argsort(-abs_coef)[:top_k]\n",
    "\n",
    "print(f\"\\nTop-{top_k} important neurons (global index → (layer, dim, weight)):\")\n",
    "for rank, k in enumerate(top_idx, start=1):\n",
    "    layer = k // hidden_dim\n",
    "    dim   = k % hidden_dim\n",
    "    w_k   = coef[k]\n",
    "    print(f\"#{rank:2d} flat={k:6d}  layer={layer:2d}  dim={dim:4d}  weight={w_k:+.5f}\")\n",
    "\n",
    "# ==========================================\n",
    "# 9. 報酬として使いやすいように、標準化済みスコアも持っておく\n",
    "#    （PPO でそのまま reward にしてもよい形）\n",
    "# ==========================================\n",
    "\n",
    "# y_pred_std_full を df_full と整合する形で格納したい場合\n",
    "y_pred_std_full = np.empty(N, dtype=np.float32)\n",
    "y_pred_std_full[idx_train] = y_train_pred_std\n",
    "y_pred_std_full[idx_test]  = y_test_pred_std\n",
    "\n",
    "df_full[\"rm_lasso_pred_std\"] = y_pred_std_full\n",
    "\n",
    "print(\"\\nSummary of rm_lasso_pred (original scale):\")\n",
    "print(df_full[\"rm_lasso_pred\"].describe())\n",
    "\n",
    "print(\"\\nSummary of rm_lasso_pred_std (z-score like):\")\n",
    "print(df_full[\"rm_lasso_pred_std\"].describe())\n",
    "\n",
    "# 必要なら保存\n",
    "# df_full.to_csv(\"df_with_lasso_rm.csv\", index=False)\n",
    "\n",
    "# ==========================================\n",
    "# 10. 後で PPO などから呼べるような状態を一つにまとめる例\n",
    "# ==========================================\n",
    "\n",
    "lasso_rm_state = {\n",
    "    \"num_layers\": num_layers,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"scaler_X_mean\": scaler_X.mean_.astype(np.float32),\n",
    "    \"scaler_X_scale\": scaler_X.scale_.astype(np.float32),\n",
    "    \"scaler_y_mean\": float(scaler_y.mean_[0]),\n",
    "    \"scaler_y_scale\": float(scaler_y.scale_[0]),\n",
    "    \"coef\": coef.astype(np.float32),\n",
    "    \"intercept\": float(lasso.intercept_),\n",
    "}\n",
    "\n",
    "# 例: joblib で保存したければ\n",
    "# import joblib\n",
    "# joblib.dump(lasso_rm_state, \"lasso_creativity_rm_state.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b1bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lasso_rm_state, \"lasso_creativity_rm_state.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4b8b46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aadbaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
